{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "colab": {
   "name": "TIUR_Set1_Quickstart.ipynb",
   "provenance": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIUR Training Tricks \u2014 Experiment Set 1 (Quickstart)\n",
    "\n",
    "This notebook runs a Colab-friendly suite of **training-trick experiments** and logs TIUR-style diagnostics:\n",
    "- loss mean + ensemble loss fluctuations\n",
    "- time-Fisher proxy (diagonal Gaussian ensemble estimate)\n",
    "- drift vs churn decomposition (`I_mu` vs `I_sigma`)\n",
    "- speed-limit efficiency `eta`\n",
    "\n",
    "**Important:** Use `Runtime \u2192 Change runtime type \u2192 GPU`.\n",
    "\n",
    "All outputs are written to **Google Drive** so you don't lose results if the Colab runtime resets.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Mount Google Drive (persistent storage)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os, time\n",
    "BASE_OUT = '/content/drive/MyDrive/tiur_tricks_results'\n",
    "run_name = time.strftime('run_%Y%m%d_%H%M%S')\n",
    "out_dir = os.path.join(BASE_OUT, run_name)\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "print('Saving outputs to:', out_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Install minimal deps\n# NOTE: Colab already includes torch + torchvision.\n# Avoid reinstalling torchvision here (it can break ABI/CUDA compatibility).\n!pip install -q tqdm pandas matplotlib\n\n# Optional (uncomment if you run fast=False and want the expanded optimizer grid)\n# !pip install -q pytorch-optimizer transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import the repo code (robust against stale imports / path collisions)\nimport os, sys\n\nREPO_DIR = '/content/tiur_tricks_colab'\nassert os.path.exists(os.path.join(REPO_DIR, 'tiur_tricks', '__init__.py')), (\n    f'Could not find repo at {REPO_DIR}. Did you unzip the repo to /content? ' \n    f'Expected {REPO_DIR}/tiur_tricks/__init__.py'\n)\n\n# Ensure our repo takes precedence over any similarly named installed package.\nif REPO_DIR not in sys.path:\n    sys.path.insert(0, REPO_DIR)\n\n# If a previous cell imported a different tiur_tricks, clear it.\nif 'tiur_tricks' in sys.modules:\n    del sys.modules['tiur_tricks']\n\nimport tiur_tricks\nprint('tiur_tricks loaded from:', getattr(tiur_tricks, '__file__', None))\n\nfrom tiur_tricks import RunConfig, make_experiment_suite_set1, run_experiment_suite\n\ndata_dir = '/content/data'  # dataset cache (not persisted; small + redownloadable)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# --- Quick suite settings (tweak these first) ---\n",
    "# For the very first run, keep it cheap. Then increase num_replicates and subset sizes.\n",
    "base = RunConfig(\n",
    "    device='cuda',\n",
    "    dataset='cifar10',\n",
    "    model='small_cnn',   # 'resnet18' is slower but more realistic\n",
    "    num_replicates=3,\n",
    "    subset_train=5000,\n",
    "    subset_eval=1000,\n",
    "    epochs=2,\n",
    "    checkpoint_every=50,\n",
    "    eval_batches=10,\n",
    ")\n",
    "\n",
    "suite = make_experiment_suite_set1(base, fast=True)\n",
    "print('Number of runs in suite:', len(suite))\n",
    "\n",
    "logs_df, summary_df = run_experiment_suite(\n",
    "    suite,\n",
    "    out_dir=out_dir,\n",
    "    data_dir=data_dir,\n",
    "    show_plots=True,\n",
    "    save_plots=True,\n",
    "    persist_checkpoints=True,\n",
    ")\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Confirm what's been written to Google Drive\n",
    "import glob\n",
    "n_files = len(glob.glob(out_dir + '/**/*', recursive=True))\n",
    "print('Total files written:', n_files)\n",
    "print('Top-level outputs:')\n",
    "!ls -lah {out_dir}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to look in Drive\n",
    "\n",
    "In your Google Drive you should now have:\n",
    "- `summary.csv` and `all_logs.csv` at the run root\n",
    "- one folder per run config (e.g. `opt_adamw/`) containing:\n",
    "  - `config.json`\n",
    "  - `logs.csv` (complete)\n",
    "  - `logs_live.csv` (written incrementally during training)\n",
    "  - `*_loss.png`, `*_fisher.png`, `*_efficiency.png`, `*_bound.png`\n"
   ]
  }
 ]
}